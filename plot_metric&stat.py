# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h6znYXgClF9hYujXtGApVjaLRz6sNfa3
"""

# ===========================================================
# SCRIPT AUTOMATIQUE POUR RÉPONDRE AUX REVIEWERS
# - Calcule mean ± SD + IC95% pour IoU / Precision / Recall / DSC
# - Calcule Wilcoxon + t-test YOLO vs U-Net
# - Fonctionne sur ~330 fichiers CSV de folds en une fois
# ===========================================================

import os
import glob
import numpy as np
import pandas as pd

# SciPy pour les tests statistiques (disponible par défaut sur Colab)
from scipy.stats import wilcoxon, ttest_rel


# ===========================================================
# 1) CONFIGURATION : À ADAPTER UNIQUEMENT ICI
# ===========================================================

# Chemin du dossier où se trouvent tous TES CSV de folds
# Exemples :
# BASE_PATH = "/content/drive/MyDrive/wound_results"
# BASE_PATH = "/mnt/data"
BASE_PATH = "/content"  # <<< MODIFIE SEULEMENT ÇA
print("Dossier existe ? ", os.path.exists(BASE_PATH))
MODELS = [
    "unet",
    "yolov8n", "yolov8s", "yolov8m", "yolov8l", "yolov8x",
    "yolo11n", "yolo11s", "yolo11m", "yolo11l", "yolo11x",
]

CONFIGS = [
    "azh", "azh_kaggle", "kaggle", "kaggle_azh", "combined_azh", "combined_kaggle",
]

for model in MODELS:
    for cfg in CONFIGS:
        pattern = f"{BASE_PATH}/result_{model}_{cfg}_fold*.csv"
        files = glob.glob(pattern)
        print(model, cfg, "->", len(files), "fichiers")



# ===========================================================
# 2) FONCTIONS UTILITAIRES
# ===========================================================
def load_fold_csv(path):
    """
    Lecture robuste d’un fichier CSV de segmentation.

    Cas gérés :
      - Fichiers U-Net (nom contenant 'unet') : toujours SANS header.
      - Fichiers YOLO :
          * soit avec header texte (threshold, iou, precision, recall, dice...)
          * soit sans header (seulement des nombres).
    Le séparateur peut être ',' ou ';'.

    Retourne un DataFrame avec colonnes :
      ['threshold', 'IoU', 'Precision', 'Recall', 'DSC']
    """

    fname = os.path.basename(path).lower()

    # ---- Lecture brute de la première ligne ----
    with open(path, "r", encoding="utf-8") as f:
        first_line = f.readline().strip()

    if not first_line:
        raise RuntimeError(f"Fichier vide : {path}")

    # Détection du séparateur
    sep = ";" if first_line.count(";") > first_line.count(",") else ","

    # ---- CAS SPÉCIAL U-NET : toujours sans header ----
    if "unet" in fname:
        try:
            df = pd.read_csv(path, sep=sep, header=None)
        except Exception as e:
            raise RuntimeError(f"Erreur lecture CSV U-Net ({path}) sep='{sep}': {e}")

        if df.shape[1] < 5:
            raise RuntimeError(f"{path}: format U-Net inattendu, <5 colonnes, shape={df.shape}")

        df = df.iloc[:, :5]
        df.columns = ["threshold", "IoU", "Precision", "Recall", "DSC"]

    else:
        # ---- YOLO : il peut y avoir ou non un header ----

        first_lower = first_line.lower()

        # On considère qu'il y a un header SEULEMENT si on voit explicitement
        # des noms de colonnes typiques
        header_keywords = ["threshold", "iou", "precision", "recall", "dice"]
        has_header = any(k in first_lower for k in header_keywords)

        if has_header:
            # Lecture avec header
            try:
                df = pd.read_csv(path, sep=sep)
            except Exception as e:
                raise RuntimeError(f"Erreur lecture CSV YOLO avec header ({path}) sep='{sep}': {e}")

            # Normalisation des noms
            col_map = {}
            for c in df.columns:
                cl = c.lower()
                if cl == "threshold":
                    col_map[c] = "threshold"
                elif cl == "iou":
                    col_map[c] = "IoU"
                elif cl == "precision":
                    col_map[c] = "Precision"
                elif cl == "recall":
                    col_map[c] = "Recall"
                elif cl in ["dice", "dice_coefficient", "dsc"]:
                    col_map[c] = "DSC"
                # les autres colonnes (accuracy, etc.) sont ignorées

            df = df.rename(columns=col_map)

            needed = ["threshold", "IoU", "Precision", "Recall", "DSC"]
            for col in needed:
                if col not in df.columns:
                    raise RuntimeError(f"{path}: colonne manquante dans fichier YOLO avec header : {col}")

            df = df[needed]

        else:
            # YOLO sans header : même traitement que U-Net mais sans le cas spécial
            try:
                df = pd.read_csv(path, sep=sep, header=None)
            except Exception as e:
                raise RuntimeError(f"Erreur lecture CSV YOLO sans header ({path}) sep='{sep}': {e}")

            if df.shape[1] < 5:
                raise RuntimeError(f"{path}: format YOLO sans header inattendu, <5 colonnes, shape={df.shape}")

            df = df.iloc[:, :5]
            df.columns = ["threshold", "IoU", "Precision", "Recall", "DSC"]

    # ---- Conversion en float ----
    for col in ["threshold", "IoU", "Precision", "Recall", "DSC"]:
        df[col] = (
            df[col]
            .astype(str)
            .str.replace(",", ".", regex=False)
            .astype(float)
        )

    return df



def parse_filename(path):
    """
    Décode le nom de fichier pour extraire :
    - model : 'unet', 'yolov8n', 'yolo11s', ...
    - config : 'azh', 'azh_kaggle', 'kaggle', 'kaggle_azh', 'combined_azh', 'combined_kaggle', etc.
    - fold : numéro de fold (1, 2, 3, 4, 5)

    Format attendu : result_<model>_<config>_foldX(.csv)
    Exemples :
      result_unet_azh_fold1.csv          -> model='unet',    config='azh'
      result_yolov8s_kaggle_fold3.csv    -> model='yolov8s', config='kaggle'
      result_yolo11n_combined_kaggle_fold5.csv -> model='yolo11n', config='combined_kaggle'
    """
    fname = os.path.basename(path)
    name = os.path.splitext(fname)[0]  # sans .csv

    if "fold" not in name:
        return None  # pas un fichier de fold

    # Sépare la partie avant "_fold" et le numéro
    try:
        left, fold_str = name.rsplit("_fold", 1)
        fold = int(fold_str)
    except Exception:
        return None

    # On s’attend à quelque chose du type "result_<model>_<config>"
    if not left.startswith("result_"):
        return None

    core = left[len("result_"):]  # enlève "result_"
    parts = core.split("_", 1)
    if len(parts) < 2:
        # pas assez d’info pour avoir model + config
        return None

    model = parts[0]
    config = parts[1]  # tout le reste (peut contenir des "_", ex: 'combined_kaggle')

    return model, config, fold


def choose_best_threshold(dfs):
    """
    Choisit le meilleur threshold pour un ensemble de folds :
    - dfs : liste de DataFrames (un par fold) avec colonnes ['threshold', 'IoU', ...]
    - Stratégie : on prend le threshold qui maximise la moyenne de IoU sur les folds.

    Retourne :
    - best_thr (float)
    """
    # On suppose que tous les folds ont les mêmes thresholds
    thresholds = sorted(dfs[0]["threshold"].unique())

    best_thr = None
    best_mean_iou = -np.inf

    for thr in thresholds:
        # Récupère les IoU de chaque fold pour ce threshold
        ious = []
        for df in dfs:
            row = df[df["threshold"] == thr]
            if not row.empty:
                i_val = float(row["IoU"].iloc[0])
                if not np.isnan(i_val):
                    ious.append(i_val)
        if len(ious) == 0:
            continue

        mean_iou = np.mean(ious)
        if mean_iou > best_mean_iou:
            best_mean_iou = mean_iou
            best_thr = thr

    if best_thr is None:
        raise RuntimeError("Impossible de trouver un threshold avec IoU non-NaN.")

    return best_thr


def summarize_model_at_threshold(dfs, thr):
    """
    Pour un ensemble de folds (liste de DataFrames) et un threshold donné,
    calcule les valeurs par fold, la moyenne, le SD et l'IC95% pour :

    - IoU
    - Precision
    - Recall
    - DSC

    Retourne un dict :
    stats[metric] = {
        "values": np.array([...]),
        "mean": float,
        "std": float,
        "ci_low": float,
        "ci_high": float
    }
    """
    metrics = ["IoU", "Precision", "Recall", "DSC"]
    data = {m: [] for m in metrics}

    for df in dfs:
        # On prend la ligne avec ce threshold (exactement)
        row = df[df["threshold"] == thr]
        if row.empty:
            # Si pour une raison quelconque le threshold exact n'existe pas,
            # on prend le plus proche
            idx = (df["threshold"] - thr).abs().argmin()
            row = df.iloc[[idx]]

        for m in metrics:
            val = float(row[m].iloc[0])
            data[m].append(val)

    stats = {}
    n = len(dfs)

    for m in metrics:
        vals = np.array(data[m], dtype=float)
        mean = vals.mean()
        std = vals.std(ddof=1) if n > 1 else 0.0
        ci_half = 1.96 * std / np.sqrt(n) if n > 1 else 0.0

        stats[m] = {
            "values": vals,
            "mean": mean,
            "std": std,
            "ci_low": mean - ci_half,
            "ci_high": mean + ci_half,
        }

    return stats


def compare_to_unet(config, model_name, stats_model, stats_unet):
    """
    Compare un modèle YOLO à U-Net pour une config donnée,
    sur IoU et DSC, avec :

    - Wilcoxon signed-rank test
    - t-test pairé

    Retourne une liste de dicts avec les résultats.
    """
    results = []
    for metric in ["IoU", "DSC"]:
        a = stats_model[metric]["values"]
        b = stats_unet[metric]["values"]

        if len(a) != len(b) or len(a) < 2:
            # Pas de test possible
            res = {
                "config": config,
                "model": model_name,
                "metric": metric,
                "wilcoxon_p": np.nan,
                "ttest_p": np.nan,
                "wilcoxon_stat": np.nan,
                "ttest_stat": np.nan,
            }
        else:
            w_stat, w_p = wilcoxon(a, b, alternative="two-sided")
            t_stat, t_p = ttest_rel(a, b)

            res = {
                "config": config,
                "model": model_name,
                "metric": metric,
                "wilcoxon_p": w_p,
                "ttest_p": t_p,
                "wilcoxon_stat": w_stat,
                "ttest_stat": t_stat,
            }
        results.append(res)

    return results


# ===========================================================
# 3) BOUCLE PRINCIPALE
# ===========================================================

def main():
    # 1. Récupérer tous les fichiers CSV de folds
    pattern = os.path.join(BASE_PATH, "*fold*.csv")
    all_files = sorted(glob.glob(pattern))

    if not all_files:
        print(f"Aucun fichier trouvé avec le pattern : {pattern}")
        return

    print(f"Nombre total de fichiers trouvés : {len(all_files)}")

    # 2. Regrouper les fichiers par (model, config)
    groups = {}  # key = (model, config) -> list of file paths

    for path in all_files:
        parsed = parse_filename(path)
        if parsed is None:
            print(f"   [IGNORÉ] Nom de fichier non reconnu : {os.path.basename(path)}")
            continue
        model, config, fold = parsed
        key = (model, config)
        groups.setdefault(key, []).append(path)

    print(f"Nombre de groupes (model, config) détectés : {len(groups)}")

    # 3. Pour chaque groupe, charger les folds, choisir le meilleur threshold,
    #    calculer stats, et stocker le tout.
    per_model_rows = []
    stats_cache = {}  # key = (model, config) -> {"thr": best_thr, "stats": stats_dict}

    for (model, config), file_list in groups.items():
        print(f"\n=== Modèle: {model} | Config: {config} ===")
        print(f"  -> {len(file_list)} fichiers de folds")

        # Charger les DataFrames de tous les folds
        dfs = []
        for p in file_list:
            df = load_fold_csv(p)
            dfs.append(df)

        # Choix du meilleur threshold (max IoU moyen)
        best_thr = choose_best_threshold(dfs)
        print(f"  Meilleur threshold (IoU moyen max) : {best_thr:.3f}")

        # Stats à ce threshold
        stats = summarize_model_at_threshold(dfs, best_thr)
        stats_cache[(model, config)] = {"thr": best_thr, "stats": stats}

        # Sauvegarde pour CSV summary_per_model_stats
        for metric, s in stats.items():
            row = {
                "model": model,
                "config": config,
                "threshold": best_thr,
                "metric": metric,
                "fold_values": ";".join(f"{v:.6f}" for v in s["values"]),
                "mean": s["mean"],
                "std": s["std"],
                "ci_low": s["ci_low"],
                "ci_high": s["ci_high"],
            }
            per_model_rows.append(row)

    # 4. Comparaisons YOLO vs U-Net (par config)
    comparison_rows = []

    # D'abord, on liste toutes les configs existantes
    configs = sorted({config for (_, config) in groups.keys()})

    for config in configs:
        # U-Net doit être présent pour cette config
        unet_key = ("unet", config)
        if unet_key not in stats_cache:
            print(f"\n[ATTENTION] Pas de U-Net pour la config '{config}' -> pas de comparaison.")
            continue

        unet_stats = stats_cache[unet_key]["stats"]

        # Comparer tous les autres modèles à U-Net
        for (model, conf) in groups.keys():
            if conf != config:
                continue
            if model == "unet":
                continue  # on ne compare pas U-Net à lui-même

            model_stats = stats_cache[(model, config)]["stats"]
            comp_results = compare_to_unet(config, model, model_stats, unet_stats)
            comparison_rows.extend(comp_results)

    # 5. Sauvegarde des résultats dans deux CSV
    per_model_df = pd.DataFrame(per_model_rows)
    comparisons_df = pd.DataFrame(comparison_rows)

    out1 = os.path.join(BASE_PATH, "summary_per_model_stats.csv")
    out2 = os.path.join(BASE_PATH, "summary_comparisons_vs_unet.csv")

    per_model_df.to_csv(out1, index=False, sep=",", quoting=1)  # QUOTE_ALL
    comparisons_df.to_csv(out2, index=False, sep=",", quoting=1)


    print("\n==================================================")
    print(f"✅ Fichier récap par modèle écrit dans : {out1}")
    print(f"✅ Fichier comparaisons YOLO vs U-Net dans : {out2}")
    print("Tu peux les ouvrir dans Excel / pandas pour récupérer les valeurs.")
    print("==================================================")


    supp_path = os.path.join(BASE_PATH, "supplementary_table_S1.csv")
    per_model_df.to_csv(supp_path, index=False)

    print(f"Supplementary table saved to: {supp_path}")

# Lancement
main()

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

# ==============================
# CONFIGURATION – À ADAPTER
# ==============================

# Racine des données
ROOT = "/path/to/your/data"  # <-- MODIFIER

# Dossiers pour chaque dataset
IMAGE_DIRS = {
    "FUSeg": os.path.join(ROOT, "FUSeg", "images"),
    "WoundData": os.path.join(ROOT, "WoundData", "images")
}

GT_DIRS = {
    "FUSeg": os.path.join(ROOT, "FUSeg", "masks_gt"),
    "WoundData": os.path.join(ROOT, "WoundData", "masks_gt")
}

UNET_DIRS = {
    "FUSeg": os.path.join(ROOT, "FUSeg", "masks_unet"),
    "WoundData": os.path.join(ROOT, "WoundData", "masks_unet")
}

YOLOV8_DIRS = {
    "FUSeg": os.path.join(ROOT, "FUSeg", "masks_yolov8"),
    "WoundData": os.path.join(ROOT, "WoundData", "masks_yolov8")
}

YOLO11_DIRS = {
    "FUSeg": os.path.join(ROOT, "FUSeg", "masks_yolo11"),
    "WoundData": os.path.join(ROOT, "WoundData", "masks_yolo11")
}

# Liste manuelle des cas à illustrer.
# Idéalement : 2 "easy" + 2 "difficult" pour FUSeg, 1–2 de chaque pour Wound Data.
# Les fichiers doivent exister dans tous les dossiers ci-dessus.
EXAMPLES = [
    # Exemple FUSeg – cas "facile" (bon IoU pour tous les modèles)
    {"dataset": "FUSeg", "filename": "fus_001.jpg", "difficulty": "easy"},
    # Exemple FUSeg – cas "difficile" (contours irréguliers, faible contraste)
    {"dataset": "FUSeg", "filename": "fus_045.jpg", "difficulty": "difficult"},
    # Exemple Wound Data – variation de couleur / illumination
    {"dataset": "WoundData", "filename": "wd_102.png", "difficulty": "color/illumination"},
    # Exemple Wound Data – ombres + contexte large
    {"dataset": "WoundData", "filename": "wd_210.png", "difficulty": "shadows/context"},
    # Tu peux en ajouter 1 ou 2 de plus si besoin :
    # {"dataset": "FUSeg", "filename": "fus_120.jpg", "difficulty": "irregular boundary"},
    # {"dataset": "WoundData", "filename": "wd_305.png", "difficulty": "challenging boundary"},
]

# Nom du fichier de sortie
OUTPUT_FIG_PATH = "qualitative_comparison_yolo_unet.png"


# ==============================
# FONCTIONS UTILITAIRES
# ==============================

def load_image(path):
    """Charge une image en RGB (uint8)."""
    img = cv2.imread(path, cv2.IMREAD_COLOR)
    if img is None:
        raise FileNotFoundError(f"Image not found: {path}")
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    return img


def load_mask(path):
    """Charge un masque binaire (0/1) à partir d'un fichier image."""
    mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    if mask is None:
        raise FileNotFoundError(f"Mask not found: {path}")
    # Binarisation robuste (au cas où la prédiction n'est pas strictement 0/255)
    _, mask_bin = cv2.threshold(mask, 0, 1, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return mask_bin.astype(np.uint8)


def overlay_mask(image, mask, color=(255, 0, 0), alpha=0.5):
    """
    Superpose un masque binaire sur une image RGB.
    color : tuple (R, G, B)
    alpha : transparence du masque
    """
    if image.dtype != np.uint8:
        image = image.astype(np.uint8)

    overlay = image.copy()
    color_layer = np.zeros_like(image, dtype=np.uint8)
    color_layer[mask > 0] = color

    cv2.addWeighted(color_layer, alpha, overlay, 1 - alpha, 0, overlay)
    return overlay


def build_paths(dataset, filename):
    """Construit les chemins vers image, GT, U-Net, YOLOv8, YOLO11 pour un exemple donné."""
    img_path = os.path.join(IMAGE_DIRS[dataset], filename)

    # On suppose que les masques ont le même nom de fichier, éventuellement avec extension modifiée.
    base_name, _ = os.path.splitext(filename)
    gt_path = os.path.join(GT_DIRS[dataset], base_name + ".png")        # adapter extension si besoin
    unet_path = os.path.join(UNET_DIRS[dataset], base_name + ".png")
    y8_path = os.path.join(YOLOV8_DIRS[dataset], base_name + ".png")
    y11_path = os.path.join(YOLO11_DIRS[dataset], base_name + ".png")

    return img_path, gt_path, unet_path, y8_path, y11_path


# ==============================
# GÉNÉRATION DE LA FIGURE
# ==============================

def create_qualitative_figure(examples, output_path):
    n_examples = len(examples)
    n_cols = 5  # Original, GT, U-Net, YOLOv8, YOLO11

    fig, axes = plt.subplots(
        nrows=n_examples,
        ncols=n_cols,
        figsize=(3 * n_cols, 3 * n_examples)
    )

    if n_examples == 1:
        # Matplotlib renvoie un axe 1D si une seule ligne
        axes = np.expand_dims(axes, axis=0)

    col_titles = ["Original", "Ground Truth", "U-Net", "YOLOv8", "YOLO11"]

    for col in range(n_cols):
        axes[0, col].set_title(col_titles[col], fontsize=12, fontweight="bold")

    for row_idx, ex in enumerate(examples):
        dataset = ex["dataset"]
        filename = ex["filename"]
        difficulty = ex.get("difficulty", "")

        img_path, gt_path, unet_path, y8_path, y11_path = build_paths(dataset, filename)

        # Chargement
        img = load_image(img_path)
        gt = load_mask(gt_path)
        unet = load_mask(unet_path)
        y8 = load_mask(y8_path)
        y11 = load_mask(y11_path)

        # Overlays (codes couleur distincts pour bien différencier les modèles)
        img_gt = overlay_mask(img, gt, color=(0, 255, 0), alpha=0.45)      # vert
        img_unet = overlay_mask(img, unet, color=(255, 0, 0), alpha=0.45)  # rouge
        img_y8 = overlay_mask(img, y8, color=(0, 0, 255), alpha=0.45)      # bleu
        img_y11 = overlay_mask(img, y11, color=(255, 165, 0), alpha=0.45)  # orange

        # Plot
        row_axes = axes[row_idx]

        # Col 0: original (before)
        row_axes[0].imshow(img)
        row_axes[0].set_ylabel(
            f"{dataset}\n{difficulty}",
            fontsize=10
        )

        # Col 1: GT
        row_axes[1].imshow(img_gt)
        # Col 2: U-Net
        row_axes[2].imshow(img_unet)
        # Col 3: YOLOv8
        row_axes[3].imshow(img_y8)
        # Col 4: YOLO11
        row_axes[4].imshow(img_y11)

        for ax in row_axes:
            ax.axis("off")

    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches="tight")
    plt.close(fig)
    print(f"Figure saved to: {output_path}")


if __name__ == "__main__":
    create_qualitative_figure(EXAMPLES, OUTPUT_FIG_PATH)